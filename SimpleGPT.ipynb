{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPKdecJfx6nr"
   },
   "source": [
    "# SimpleGPT\n",
    "\n",
    "The objective of this notebook is to create and train a decoder-only model, which is a custom and scaled-down version of GPT, using the specified dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmDJ5RdJpJX3"
   },
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfztaXelrAjB"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import PyTorch and submodules for neural network construction and operations\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74cxkR23o-Rq"
   },
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xEXE-Xszqw46",
    "outputId": "d85ed445-538e-4d43-a257-f3e8e89df47b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-21 15:45:54--  https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-08/friends.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5383844 (5.1M) [text/plain]\n",
      "Saving to: ‘friends.csv’\n",
      "\n",
      "friends.csv         100%[===================>]   5.13M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2024-04-21 15:45:55 (93.1 MB/s) - ‘friends.csv’ saved [5383844/5383844]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-08/friends.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvxCSyzlpbfs"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlT1e6J8NxDd",
    "outputId": "80e5bfab-62ba-4838-c83f-4cdce4400cee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7df800776e90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "block_size = 32  # Length of sequence fed into the model\n",
    "max_iters = 5000  # Maximum number of training iterations\n",
    "eval_interval = 100  # Interval for evaluating the model on validation data\n",
    "learning_rate = 1e-3\n",
    "\n",
    "n_embd = 64  # Dimensionality of the embeddings\n",
    "n_head = 4   # Number of attention heads\n",
    "n_layer = 4  # Number of transformer layers\n",
    "\n",
    "eval_iters = 200  # Number of iterations to run during evaluation\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(1337)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciQtkU4spQIA"
   },
   "source": [
    "## Preparing dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "LnC75YdYIFVv",
    "outputId": "94bd2467-0400-449f-cec6-5eaf97c7debf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"friends_df\",\n  \"rows\": 67373,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56920,\n        \"samples\": [\n          \"Yeah, about 300 guys I went to high school with. Yeah, thanks.\",\n          \"How weird is that? Y'know? You're moving in with me and have the one thing I don't have. It's like uh, in a way you-you complete me kitchen.\",\n          \"Howard's the handy man!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 699,\n        \"samples\": [\n          \"Friend\",\n          \"The Second Guest\",\n          \"A Drunken Gambler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"episode\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 25,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          9,\n          17,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scene\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 29,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          28,\n          17,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"utterance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 0,\n        \"max\": 255,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          228,\n          7,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "friends_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e2fa3e20-cbcd-426f-a4f2-de24a4c73f02\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>season</th>\n",
       "      <th>episode</th>\n",
       "      <th>scene</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's nothing to tell! He's just some guy I ...</td>\n",
       "      <td>Monica Geller</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C'mon, you're going out with the guy! There's ...</td>\n",
       "      <td>Joey Tribbiani</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All right Joey, be nice. So does he have a hum...</td>\n",
       "      <td>Chandler Bing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wait, does he eat chalk?</td>\n",
       "      <td>Phoebe Buffay</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(They all stare, bemused.)</td>\n",
       "      <td>Scene Directions</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2fa3e20-cbcd-426f-a4f2-de24a4c73f02')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e2fa3e20-cbcd-426f-a4f2-de24a4c73f02 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e2fa3e20-cbcd-426f-a4f2-de24a4c73f02');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-b6763a83-f560-421b-8854-0c34518fe278\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6763a83-f560-421b-8854-0c34518fe278')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-b6763a83-f560-421b-8854-0c34518fe278 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text           speaker  \\\n",
       "0  There's nothing to tell! He's just some guy I ...     Monica Geller   \n",
       "1  C'mon, you're going out with the guy! There's ...    Joey Tribbiani   \n",
       "2  All right Joey, be nice. So does he have a hum...     Chandler Bing   \n",
       "3                           Wait, does he eat chalk?     Phoebe Buffay   \n",
       "4                         (They all stare, bemused.)  Scene Directions   \n",
       "\n",
       "   season  episode  scene  utterance  \n",
       "0       1        1      1          1  \n",
       "1       1        1      1          2  \n",
       "2       1        1      1          3  \n",
       "3       1        1      1          4  \n",
       "4       1        1      1          5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_df = pd.read_csv('friends.csv')\n",
    "friends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "k-f3eh9aJ-lI",
    "outputId": "dbc68860-0cb8-4e3e-d4cd-d4d84a2a833d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"friends_df\",\n  \"rows\": 61034,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51248,\n        \"samples\": [\n          \"Yeah, Charlie is gonna be joining my department.\",\n          \"All right. I can't see.\",\n          \"Ross? Ross! Wake up! Ross! Ross! Ross!! Ross!!! Ross!!!!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 463,\n        \"samples\": [\n          \"Rick\",\n          \"Both\",\n          \"Mr.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "friends_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-1ca7e625-91e6-41cc-888e-8c792a7cca26\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's nothing to tell! He's just some guy I ...</td>\n",
       "      <td>Monica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C'mon, you're going out with the guy! There's ...</td>\n",
       "      <td>Joey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All right Joey, be nice. So does he have a hum...</td>\n",
       "      <td>Chandler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wait, does he eat chalk?</td>\n",
       "      <td>Phoebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Just, 'cause, I don't want her to go through w...</td>\n",
       "      <td>Phoebe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ca7e625-91e6-41cc-888e-8c792a7cca26')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1ca7e625-91e6-41cc-888e-8c792a7cca26 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1ca7e625-91e6-41cc-888e-8c792a7cca26');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-6f1def60-2aec-4968-a71d-1b0bb0b8950a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f1def60-2aec-4968-a71d-1b0bb0b8950a')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-6f1def60-2aec-4968-a71d-1b0bb0b8950a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text   speaker\n",
       "0  There's nothing to tell! He's just some guy I ...    Monica\n",
       "1  C'mon, you're going out with the guy! There's ...      Joey\n",
       "2  All right Joey, be nice. So does he have a hum...  Chandler\n",
       "3                           Wait, does he eat chalk?    Phoebe\n",
       "5  Just, 'cause, I don't want her to go through w...    Phoebe"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_df = friends_df.drop(['episode','season','scene','utterance'], axis='columns')\n",
    "friends_df = friends_df[friends_df['speaker'].str.contains('Scene')==False].copy()\n",
    "friends_df['speaker'] = friends_df['speaker'].apply(lambda sp: sp.lower().capitalize().split(' ')[0])\n",
    "\n",
    "friends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xP9TzA7BqwlZ",
    "outputId": "c70fcab8-9a3d-4b0a-9aed-256df36c56f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset in characters: 3774765\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset text\n",
    "text = '\\n\\n'.join(f\"{row['speaker']}:\\n{row['text']}\" for _, row in friends_df.iterrows())\n",
    "print(\"Length of dataset in characters:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c5V0FvqseE0",
    "outputId": "00b47804-d7e1-4e5b-f1e6-14d0c2d3aeb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monica:\n",
      "There's nothing to tell! He's just some guy I work with!\n",
      "\n",
      "Joey:\n",
      "C'mon, you're going out with the guy! There's gotta be something wrong with him!\n",
      "\n",
      "Chandler:\n",
      "All right Joey, be nice. So does he have a hump? A hump and a hairpiece?\n",
      "\n",
      "Phoebe:\n",
      "Wait, does he eat chalk?\n",
      "\n",
      "Phoebe:\n",
      "Just, 'cause, I don't want her to go through what I went through with Carl- oh!\n",
      "\n",
      "Monica:\n",
      "Okay, everybody relax. This is not even a date. It's just two people going out to dinner and- not having sex.\n",
      "\n",
      "Chandler:\n",
      "Sounds like a date to me.\n",
      "\n",
      "Chandler:\n",
      "Alright, so I'm back in high school, I'm standing in the middle of the cafeteria, and I realize I am totally naked.\n",
      "\n",
      "#all#:\n",
      "Oh, yeah. Had that dream.\n",
      "\n",
      "Chandler:\n",
      "Then I look down, and I realize there's a phone... there.\n",
      "\n",
      "Joey:\n",
      "Instead of...?\n",
      "\n",
      "Chandler:\n",
      "That's right.\n",
      "\n",
      "Joey:\n",
      "Never had that dream.\n",
      "\n",
      "Phoebe:\n",
      "No.\n",
      "\n",
      "Chandler:\n",
      "All of a sudden, the phone starts to ring. Now I don't know what to do, everybody starts looking at me.\n",
      "\n",
      "Monica:\n",
      "And they weren't looking at you before?!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the first 1000 characters of the dataset text\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLYd4qOGN04D"
   },
   "outputs": [],
   "source": [
    "# Create a vocabulary and encode/decode functions\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "char_to_id = {ch: i for i, ch in enumerate(chars)}\n",
    "id_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "def encode(string):\n",
    "    return [char_to_id[char] for char in string]\n",
    "\n",
    "def decode(ids):\n",
    "    return ''.join(id_to_char[id] for id in ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-X_Pb0b7N225",
    "outputId": "844faeeb-a7ed-4c33-84b6-88f25470fd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 88\n",
      "Training Data Length: 3397288\n",
      "Validation Data Length: 377477\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for model training\n",
    "data = torch.LongTensor(encode(text))\n",
    "train_part = int(0.9 * len(data))\n",
    "train_data, val_data = data[:train_part], data[train_part:]\n",
    "\n",
    "\n",
    "# Display information about the prepared data\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "print(f\"Training Data Length: {len(train_data)}\")\n",
    "print(f\"Validation Data Length: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4FsOCySpw95"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5BQ7pW_B9ISD"
   },
   "outputs": [],
   "source": [
    "s=nn.Embedding(vocab_size=3000, n_embd=1024).to(device)\n",
    "m=MultiHeadSelfAttention(num_heads=4, n_embd=1024, head_size=12).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxuew6b59QQF",
    "outputId": "9f17e493-c844-4e49-ecb8-474cf1f6d97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32])\n"
     ]
    }
   ],
   "source": [
    "x=get_random_batch(train_data, block_size, batch_size)[0]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GuNeXRII9Y4L",
    "outputId": "4bc80d36-c95b-42cc-98a1-d036576f2c11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=s(x)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wu21-_C1KPjM"
   },
   "outputs": [],
   "source": [
    "def get_random_batch(data_source, block_size, batch_size):\n",
    "    \"\"\"\n",
    "    Generates a random batch of input and label tensors from the data source.\n",
    "\n",
    "    Parameters:\n",
    "    - data_source: The dataset from which to sample.\n",
    "    - block_size: The size of each sequence to be sampled.\n",
    "    - batch_size: The number of sequences per batch.\n",
    "\n",
    "    \"\"\"\n",
    "    indices = torch.randint(high=len(data_source) - block_size, size=(batch_size,))\n",
    "    inputs = torch.stack([data_source[idx: idx + block_size] for idx in indices]).to(device)\n",
    "    labels = torch.stack([data_source[idx + 1: idx + block_size + 1] for idx in indices]).to(device)\n",
    "    return inputs, labels\n",
    "\n",
    "\n",
    "def estimate_loss(model, data_sources, block_size, batch_size, eval_iters):\n",
    "    \"\"\"\n",
    "    Estimates the model's loss on different data splits.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to evaluate.\n",
    "    - data_sources: A dictionary of datasets for each split.\n",
    "    - block_size: The size of each sequence block.\n",
    "    - batch_size: The number of sequences per batch.\n",
    "    - eval_iters: The number of iterations for evaluation.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    losses_dict = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for split, data_source in data_sources.items():\n",
    "            losses = [model(*get_random_batch(data_source, block_size, batch_size))[1].item() for _ in range(eval_iters)]\n",
    "            losses_dict[split] = torch.tensor(losses).mean()\n",
    "    model.train()\n",
    "    return losses_dict\n",
    "\n",
    "def generate_text(model, initial_idx, block_size, max_new_tokens):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to use for text generation.\n",
    "    - initial_idx: The initial indices for generation.\n",
    "    - block_size: The size of the block to consider for each prediction.\n",
    "    - max_new_tokens: The maximum number of tokens to generate.\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    idx = initial_idx\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, _ = model(idx_cond)\n",
    "            probs = F.softmax(logits[:, -1, :], dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "    model.train()\n",
    "    return idx\n",
    "\n",
    "\n",
    "def train_model(model, train_data, val_data, block_size, batch_size, max_iters, eval_interval, optimizer):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    - model: The model to train.\n",
    "    - train_data: The training dataset.\n",
    "    - val_data: The validation dataset.\n",
    "    - block_size: The size of each sequence block.\n",
    "    - batch_size: The number of sequences per batch.\n",
    "    - max_iters: The maximum number of iterations for training.\n",
    "    - eval_interval: The interval at which to evaluate the model.\n",
    "    - optimizer: The optimizer for training the model.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    data_sources = {'train': train_data, 'val': val_data}\n",
    "    for iteration in range(max_iters):\n",
    "        if iteration % eval_interval == 0 or iteration == max_iters - 1:\n",
    "            losses = estimate_loss(model, data_sources, block_size, batch_size, eval_iters)\n",
    "            print(f\"Iteration {iteration}: Train Loss {losses['train']:.4f}, Val Loss {losses['val']:.4f}\")\n",
    "\n",
    "        inputs, labels = get_random_batch(train_data, block_size, batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        _, loss = model(inputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzHTTdxvqH1s"
   },
   "source": [
    "## Transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87TGFQqFN-g2"
   },
   "outputs": [],
   "source": [
    "class SelfAttentionHead(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_embd, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head_size =head_size\n",
    "        self.key = nn.Linear(n_embd, n_embd,bias=False)\n",
    "        self.query = nn.Linear(n_embd, n_embd,bias=False)\n",
    "        self.value = nn.Linear(n_embd, n_embd,bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        key = self.key(x)\n",
    "        query = self.query(x)\n",
    "        value = self.value(x)\n",
    "\n",
    "        attn_scores = torch.matmul(query, key.transpose(-2, -1)) / (self.head_size ** 0.5)\n",
    "\n",
    "        seq_length = x.size(1)\n",
    "        mask = torch.tril(torch.ones(seq_length, seq_length)).to(x.device)\n",
    "\n",
    "        attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "        out = torch.matmul(attn_weights, value)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, num_heads, n_embd, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.heads =nn.ModuleList([SelfAttentionHead(n_embd, head_size) for _ in range(num_heads)])\n",
    "        self.projection =nn.Linear(num_heads * head_size, n_embd)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Compute self-attention for each head\n",
    "        attn_outputs = [head(x) for head in self.heads]\n",
    "\n",
    "        # Concatenate the outputs from all heads\n",
    "        combined_attn = torch.cat(attn_outputs, dim=-1)\n",
    "\n",
    "        # Project the concatenated outputs back to the input size\n",
    "        out = self.projection(combined_attn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "\n",
    "        self.forward_expansion=4\n",
    "        self.net =self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, self.forward_expansion * n_embd),  # You can adjust the hidden layer size as needed\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.forward_expansion * n_embd, n_embd)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        output = self.net(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luJq9Za7osBU"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, n_embd, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attention =MultiHeadSelfAttention(num_heads, n_embd, head_size=64)\n",
    "        self.feed_forward =FeedForward(n_embd)\n",
    "        self.norm1 =nn.LayerNorm(n_embd)\n",
    "        self.norm2 =nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        attn_output = self.self_attention(x)\n",
    "        x = self.norm1(x + attn_output)\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + ff_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FjyRYGsqQ8h"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoelkOrFY8bN"
   },
   "outputs": [],
   "source": [
    "class SimpleGPT(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, vocab_size, n_embd, block_size, n_layer, n_head):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embeddings =nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embeddings =nn.Embedding(block_size, n_embd)\n",
    "        self.blocks =nn.Sequential(*[TransformerBlock(n_embd, n_head) for _ in range(n_layer)])\n",
    "        self.layer_norm = nn.LayerNorm(n_embd)\n",
    "        self.lm_head =nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "\n",
    "\n",
    "        token_embeds = self.token_embeddings(idx)\n",
    "        seq_length = idx.size(1)\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=idx.device)\n",
    "        position_embeds = self.position_embeddings(position_ids)\n",
    "\n",
    "        embeddings = token_embeds + position_embeds\n",
    "\n",
    "        hidden_states = self.blocks(embeddings)\n",
    "        normed_states = self.layer_norm(hidden_states)\n",
    "        logits = self.lm_head(normed_states)\n",
    "\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YbS3pJH0RL65",
    "outputId": "61a14846-5643-4bc6-dc44-f2d202502ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters = 409304\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model and move it to the appropriate device\n",
    "model = SimpleGPT(vocab_size=vocab_size, n_embd=n_embd, block_size=block_size, n_layer=n_layer, n_head=n_head).to(device)\n",
    "\n",
    "# Calculate the number of parameters in the model\n",
    "num_parameters = sum(p.numel() for p in model.parameters())\n",
    "print(f'Number of parameters = {num_parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45LGegT3W86c",
    "outputId": "49286442-62c5-4fd5-820f-cac8d97d0ff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleGPT(\n",
      "  (token_embeddings): Embedding(88, 64)\n",
      "  (position_embeddings): Embedding(32, 64)\n",
      "  (blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (self_attention): MultiHeadSelfAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x SelfAttentionHead(\n",
      "            (key): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (query): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (value): Linear(in_features=64, out_features=64, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (projection): Linear(in_features=256, out_features=64, bias=True)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (self_attention): MultiHeadSelfAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x SelfAttentionHead(\n",
      "            (key): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (query): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (value): Linear(in_features=64, out_features=64, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (projection): Linear(in_features=256, out_features=64, bias=True)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (self_attention): MultiHeadSelfAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x SelfAttentionHead(\n",
      "            (key): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (query): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (value): Linear(in_features=64, out_features=64, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (projection): Linear(in_features=256, out_features=64, bias=True)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (self_attention): MultiHeadSelfAttention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x SelfAttentionHead(\n",
      "            (key): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (query): Linear(in_features=64, out_features=64, bias=False)\n",
      "            (value): Linear(in_features=64, out_features=64, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (projection): Linear(in_features=256, out_features=64, bias=True)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): Linear(in_features=64, out_features=88, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model structure\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GE4lP5yNqY62"
   },
   "source": [
    "# training and evaluation the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Ij6iV37ROZo",
    "outputId": "dbdc44b7-1302-4716-e3c6-cae61973a164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hYpn+grS?HS9LKgbs%HhS:7gu%Mz_6\n",
      "Jx!;j_S8-Je,\"}MFIAaO:&(mAuUy+O7(ICPF17D r_Pu89`bYK;_Ea'_lm1 LFT,AHIgMj1b(t8;l?rSjN/0$IGe1e!nmEF\n",
      "GWx#\"18_WN{QIqaYh!#DtyE*oL!u8,%AM( Qc{M&0'VuKj**TAEm3o2s*Zm2 0_AFC-yYES 2'A2C}m}gERJU!CMT5TRV1hrgK1zy&Pi*(YKAmqaJdg+C`j*8mQB$F(Cb_d'8j$k-yCA4Sw-NBXIG&QOa40RYS1\n",
      "tTYb5yU98_ASSY2WIE&Axw#>tRD.M4QJ(m8mkAh& h8\"3Hg0Bg9\"jPc#\"1[tX&7&(\n",
      ",M&csA,\n",
      "y,7SkwUVaKZkXE!, gW**(*>SP!7g)Na_yNMd\"NT8C0t_b%Nn18;n/+mFE$A+w'CZ36&97JS!qwjJhJ#Q&)\n",
      "AZLCICE2\"!n0$p{uGga`Qp 69kSylCZ+,jd3?Zp myU9#NV{vNK!985Sjm0 kwC;Sq?52l'C,{jFEyE2hy?CA+U lJnA *0{E[9'&}i6*U9}pYYhmp;1,ZyI5?G*\"\"&f*JuE{82bjjK0i`OmJc40'Brmr8K\"  NaXUh_[A1/_m8gOT'U}\n",
      "m0QIWmk5+T8YzufRSki[GfeFX;q,Jjo!aTa(m7&j+,.j+gm\n",
      "'cu;Bg1$Sw&awv63'Qw}fuA`Ug#ysEcDg+M?e}F,7u)h_J\"H2.rgka[K;S&+?SGCA&(yz{8CKCpk1%tcUtYt2pHyAqJJuISp!:hF1abK&0'\n",
      "$bbo{ S !x'a/vACUTj}1k%pgYc>9CTTqtV+$;2oaXo:G1p}SP4Q2t;,+9c3UQjS\n",
      "JlYHp#FV2QC${tF. EU1dtSMp74Ke3Wqj8Ql2w{_VWnVQR/a M y(}U9 c?Xnj_2ylc b8nwoMVOmQt_gK\"mm{&(0P-TE>(JSt{;Xwo}AG8:\n",
      "1nF\n",
      "N7ggkBRbZAK%#7QaG\"EWg_\n",
      "m%ENfv`*YdpvSE*O2{AM8Bo(_*I-gu\n",
      "J&),'%N1>QyEm>_bp?VS*2Oh;A78? #K#Ca r%l(K{F 7;NAIoABFDVR#}jtB9}oc[+A\n",
      "!\n",
      "'f8V%1UZlsa UhAo[j:S9CAjb7(AQuaAjG2m&  cnj:Oh}GEwW!s&93gBLqK\n",
      "Yn EN6j\"&\n",
      "!0)JAYhp\n",
      "'4VQ\n",
      "UyKIo11?8j5K$E,yzjtaFKS&Iy&;QsS-E,{otT !h,IlzYT7J?7Ht?HQAF:cobe 7PQmyj>H\n",
      "}&\"MCGW,AmAQ)*_Ar FRocJsdNbtg3!&h1R#_U9BE-T6JUmW3!OY$8u\n",
      "W:C9CJEj97Rqy$'cE7($GB9Ar8Y`P_(+:CA!,3Y,}9u?2>*> 6B9oP+'*nmtR'6TJ_>ZjE>2I$ATwmY {a\"m(rwyj[3J;&g3#C2(C oaA.e:q?'?GthoA8sfTVaj3l!M*!4s}J*UYhc&gQCwMuV`3_2YU Bg+0kkhM BtU5'{KTYOX}CQiE'EQ)Yx8\"?-C?o,Bm?8TIp?jM\n",
      "Ml(-mA yuC\n",
      "R}b3'(`S}neX&UK1?7x1gmal{*1}Acpl (j1lSI&2IA}Kzl1)p:D!'XK;mM,7:*b#HoJoCs{smyo\n",
      "Ye:on\n",
      "80xav7q-KlLc{pQ+rSk6UhS7jFdHX##N} oeHC2{+\n",
      "$'!sE3,mK&{7oHbr72' IA8$0!o2IZp4,DOua_iIC{J4K8n1UmP{{%7,U6II{&;$;wO%o2Y_Em34DenbKpJ\n",
      "PJff#E$C&?}8$ YaST.FC{#N2;u_ I4HP)f3Z?EEhaK!3A%_+(pUS7OH$KuW{T+_,IjPr{A,Yb{yu'!x#fvVjIC{3/-m$;4ls!1_bvpHt2sxm\"$1QS&2a$TbEq+?  x`A${NRHqF&vQwt yoKFIvH*\"AS)s2&7!'>VC`1,ezt3dtXUoes%!j9Oi!+u7}uMwz%?53IjJ}5YDC\"0omhj*\n",
      "%}5gs{;? XICDV9A,k4VYN\" jL/AV$t1N#m8,qL!t1JwDU(&oo86G2Pl}75>!(8\n",
      "x{;3\n"
     ]
    }
   ],
   "source": [
    "# Example of generating output with the initial model (before training)\n",
    "initial_idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_output = generate_text(model, initial_idx, block_size, max_new_tokens=2000)\n",
    "decoded_output = decode(generated_output[0].tolist())\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1524iCrPffs",
    "outputId": "fac16e0a-1999-4ecc-e897-eacd564cd427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Train Loss 4.5841, Val Loss 4.5871\n",
      "Iteration 100: Train Loss 2.4675, Val Loss 2.4640\n",
      "Iteration 200: Train Loss 2.1891, Val Loss 2.2045\n",
      "Iteration 300: Train Loss 2.0026, Val Loss 2.0233\n",
      "Iteration 400: Train Loss 1.9201, Val Loss 1.9123\n",
      "Iteration 500: Train Loss 1.8115, Val Loss 1.8390\n",
      "Iteration 600: Train Loss 1.7804, Val Loss 1.7962\n",
      "Iteration 700: Train Loss 1.7209, Val Loss 1.7691\n",
      "Iteration 800: Train Loss 1.7065, Val Loss 1.7153\n",
      "Iteration 900: Train Loss 1.6792, Val Loss 1.6954\n",
      "Iteration 1000: Train Loss 1.6332, Val Loss 1.6754\n",
      "Iteration 1100: Train Loss 1.6185, Val Loss 1.6560\n",
      "Iteration 1200: Train Loss 1.5994, Val Loss 1.6320\n",
      "Iteration 1300: Train Loss 1.5917, Val Loss 1.6215\n",
      "Iteration 1400: Train Loss 1.5747, Val Loss 1.5973\n",
      "Iteration 1500: Train Loss 1.5563, Val Loss 1.5811\n",
      "Iteration 1600: Train Loss 1.5501, Val Loss 1.5800\n",
      "Iteration 1700: Train Loss 1.5315, Val Loss 1.5773\n",
      "Iteration 1800: Train Loss 1.5451, Val Loss 1.5532\n",
      "Iteration 1900: Train Loss 1.5333, Val Loss 1.5610\n",
      "Iteration 2000: Train Loss 1.5243, Val Loss 1.5308\n",
      "Iteration 2100: Train Loss 1.5141, Val Loss 1.5345\n",
      "Iteration 2200: Train Loss 1.5031, Val Loss 1.5320\n",
      "Iteration 2300: Train Loss 1.4976, Val Loss 1.5174\n",
      "Iteration 2400: Train Loss 1.4949, Val Loss 1.5159\n",
      "Iteration 2500: Train Loss 1.4822, Val Loss 1.5070\n",
      "Iteration 2600: Train Loss 1.4704, Val Loss 1.5064\n",
      "Iteration 2700: Train Loss 1.4717, Val Loss 1.5091\n",
      "Iteration 2800: Train Loss 1.4780, Val Loss 1.4989\n",
      "Iteration 2900: Train Loss 1.4609, Val Loss 1.4900\n",
      "Iteration 3000: Train Loss 1.4442, Val Loss 1.4920\n",
      "Iteration 3100: Train Loss 1.4410, Val Loss 1.4848\n",
      "Iteration 3200: Train Loss 1.4622, Val Loss 1.4815\n",
      "Iteration 3300: Train Loss 1.4409, Val Loss 1.4635\n",
      "Iteration 3400: Train Loss 1.4338, Val Loss 1.4622\n",
      "Iteration 3500: Train Loss 1.4370, Val Loss 1.4698\n",
      "Iteration 3600: Train Loss 1.4474, Val Loss 1.4677\n",
      "Iteration 3700: Train Loss 1.4348, Val Loss 1.4763\n",
      "Iteration 3800: Train Loss 1.4253, Val Loss 1.4584\n",
      "Iteration 3900: Train Loss 1.4344, Val Loss 1.4594\n",
      "Iteration 4000: Train Loss 1.4183, Val Loss 1.4591\n",
      "Iteration 4100: Train Loss 1.4104, Val Loss 1.4588\n",
      "Iteration 4200: Train Loss 1.4179, Val Loss 1.4489\n",
      "Iteration 4300: Train Loss 1.3972, Val Loss 1.4514\n",
      "Iteration 4400: Train Loss 1.4119, Val Loss 1.4494\n",
      "Iteration 4500: Train Loss 1.4218, Val Loss 1.4413\n",
      "Iteration 4600: Train Loss 1.4100, Val Loss 1.4460\n",
      "Iteration 4700: Train Loss 1.4199, Val Loss 1.4326\n",
      "Iteration 4800: Train Loss 1.3985, Val Loss 1.4242\n",
      "Iteration 4900: Train Loss 1.3921, Val Loss 1.4256\n",
      "Iteration 4999: Train Loss 1.3905, Val Loss 1.4291\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "trained_model = train_model(model, train_data, val_data, block_size, batch_size, max_iters, eval_interval, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpfsjY2ayQE-",
    "outputId": "35ed193c-dd48-445b-8b55-72fc4e95f4e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Then:\n",
      "I've too!\n",
      "\n",
      "Susan:\n",
      "Corld-Bain plofe.\n",
      "\n",
      "Riker:\n",
      "Uhm.\n",
      "\n",
      "Rachel:\n",
      "Oh no.\n",
      "\n",
      "Jane:\n",
      "Phoebe's retty what are yard?\n",
      "\n",
      "Phoebe:\n",
      "So... All He supe ergother all talked heoping thang, that happy us up.\n",
      "\n",
      "Ross:\n",
      "What?!\n",
      "\n",
      "Rachel:\n",
      "Honey, guys out who didn't her metate.\n",
      "\n",
      "Frank:\n",
      "Your honey?\n",
      "\n",
      "Chandler:\n",
      "Oh don't you.\n",
      "\n",
      "Monica:\n",
      "Donet my stupid a floon hark mainer today, you knice inve?\n",
      "\n",
      "Joey:\n",
      "Well, you've get n't olvel this some him of boonsh this a money clork about make forgot of Papoti to makes a too!\n",
      "\n",
      "Thankler:\n",
      "I'm sorry, and of a'fore together nothing.\n",
      "\n",
      "Joey:\n",
      "OK. Your and tealthing.\n",
      "\n",
      "Ross:\n",
      "Oh, hey, happy presting!\n",
      "\n",
      "Ross:\n",
      "Acrowy if chance bad on. Emma! Humm y'know gotta with her.\n",
      "\n",
      "Esomeon# of decide stupid to for that is at without?\n",
      "\n",
      "Ross:\n",
      "Yeah, we over Sary Someroma affect of it a wople her earrily, huses, C'lon't tome on-oy money.home fortant our sewing a ban loge this is of they and coolloidebe, Planing pize?\n",
      "\n",
      "Ross:\n",
      "Great is doing.\n",
      "\n",
      "Chandler:\n",
      "Okay.\n",
      "\n",
      "Monica:\n",
      "Yeah?\n",
      "\n",
      "Phoebe:\n",
      "Roch!\n",
      "\n",
      "Phoebe:\n",
      "I called?\n",
      "\n",
      "Pholebe:\n",
      "Yeah, but I can't just contal, joke over Scosloge.\n",
      "\n",
      "Rachel:\n",
      "Um, yeah, that's and evenyain! In you girl over my dase, we's gonna go. How do we divoly my packly for a doon and Monica masing Thang as aniga. Bob of a jactime brittHer nagel passart of cheatse Chimfie and off uses, okay?\n",
      "\n",
      "Monica:\n",
      "Hi. That's just rolf my resoagle! Oko. Day, we don't gonna come make a fame milk. Why erowouh?\n",
      "\n",
      "Chandler:\n",
      "This is your Chandle, deformmy some was go.\n",
      "\n",
      "Phoebe:\n",
      "Oh. Ban. Ockay invin the Tag from please is onder, some offeras as the his osplaf. You gotaOk, I come on. Those today is!\n",
      "\n",
      "Monica:\n",
      "I can't beaugh, I had me take to mean come baby good Mamm them at her back!\n",
      "\n",
      "Monica:\n",
      "Ahn okay Ealled!\n",
      "\n",
      "Rachel:\n",
      "Well Itidend a mom?\n",
      "\n",
      "Ross, Rapantbe:\n",
      "Okay, for guy thurw And waiting up?\n",
      "\n",
      "Chandler:\n",
      "Look, conicover. We got you?\n",
      "\n",
      "Rachel:\n",
      "I-I'd have !\n",
      "\n",
      "Rachel:\n",
      "Momm. Handreed that.\n",
      "\n",
      "Rachel:\n",
      "Oh.\n",
      "\n",
      "Ross:\n",
      "Shoop! Him!\n",
      "\n",
      "Randma:\n",
      "Mh-what if key. I think if her Jusly you.\n",
      "\n",
      "Joey:\n",
      "Hmmmmm you gues.\n",
      "\n",
      "Chandler:\n",
      "Oh-hoh-has ner.\n",
      "\n",
      "Moni\n"
     ]
    }
   ],
   "source": [
    "# Example of generating output with the trained model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_output = generate_text(trained_model, initial_idx, block_size, max_new_tokens=2000)\n",
    "decoded_output = decode(generated_output[0].tolist())\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvjP74BOwFrZ",
    "outputId": "b2d7fcab-9bc0-472c-c52e-63ba34aa08b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phoebe:\n",
      "Your kids!\n",
      "\n",
      "Joey:\n",
      "Go, am .I need us tole hated. She's?\n",
      "\n",
      "Joey:\n",
      "Wela:\n",
      "Joey!\n",
      "\n",
      "Morry:\n",
      "Okay! Mo, actually's on no!\n",
      "\n",
      "Rachel:\n",
      "Have yee toinglo, he same her married am-my stort!\n",
      "\n",
      "Awhen:\n",
      "Mo-let's quepian, but be us.\n",
      "\n",
      "Ross:\n",
      "Handme us a little brit! Chandler!\n",
      "\n",
      "Monica:\n",
      "All right a time and uh opa that Joey Greet I can at our listle and told good some when.\n",
      "\n",
      "Chandler:\n",
      "So you check we-wear necard chableth a baloue maginal so reft, and hole you treek up, oo-uh, okay, foush.. Oh, the gonna do!\"No.\n",
      "\n",
      "Monica:\n",
      "What huh?\n",
      "\n",
      "Monica:\n",
      "Hey!\n",
      "\n",
      "Sthank:\n",
      "Umm, it's some chass a Dilse Joey.\n",
      "\n",
      "Rachel:\n",
      "So, Chandlearw a-leasten' pliess isn't one chose that to him a failf come on! Your show guy.\n",
      "\n",
      "Janie:\n",
      "What?hat I'm just doing here upm, okay there. We're gonna go! does those that it comptimes fly at that made little again Rell whole home.\n",
      "\n",
      "Ross:\n",
      "That's day. Some Phoebe, really any lace how that grest.\n",
      "\n",
      "Rachel:\n",
      "Hi, all you call!\n",
      "\n",
      "Joey:\n",
      "Huh?! Right!!\n",
      "\n",
      "Monica:\n",
      "Rella!\n",
      "\n",
      "Rachel:\n",
      "Oh God! Rachel!\n",
      "\n",
      "Marry:\n",
      "See I can't rest.\n",
      "\n",
      "Ross:\n",
      "Hey, what is in my Carol!! What a's on that.\n",
      "\n",
      "Ross:\n",
      "Oh, you come on, in I mase this ip of plike whole!\n",
      "\n",
      "Chandler:\n",
      "Smay those zookes lace.\n",
      "\n",
      "Rachel:\n",
      "Oh, Ross's anything is a night. See.\n",
      "\n",
      "Ross:\n",
      "No! Rachel then't ream, shoe! Maybe is you!\n",
      "\n",
      "Monica:\n",
      "No. Phoeble, my ssation your doon a looket. This parennant one olther!\n",
      "\n",
      "Ke:\n",
      "Yeah, her again.\n",
      "\n",
      "Chandlearly:\n",
      "We're gonna complete door. That's straling me!\n",
      "\n",
      "Bonna:\n",
      "Oh my know.\n",
      "\n",
      "Rachel:\n",
      "Oh my roateen yeah.\n",
      "\n",
      "Joey:\n",
      "Ola can, was antlead good, I don't want through Janile kites in it you guys us?\n",
      "\n",
      "Ross:\n",
      "Heash a hope reoom is if some crabs bre. If you gotta.\n",
      "\n",
      "Ross:\n",
      "I don't the conliod.\n",
      "Chandler:\n",
      "Umt, but her cope up half to me with that night a touche Sure job.\n",
      "\n",
      "Cher:\n",
      "Oh!\n",
      "\n",
      "Chandler:\n",
      "You cadersic Bag?\n",
      "\n",
      "Chandler:\n",
      "OKaturo breave the favola comable?\n",
      "\n",
      "Monica:\n",
      "Okay. Ma\", is woman my fride Okay...\n",
      "\n",
      "Chandler:\n",
      "Uh, that's mazy then't been sweried of coathe. It'd tovag Jern.\n",
      "\n",
      "Chandler:\n",
      "We're gonna hot in that?\n",
      "\n",
      "Monica:\n",
      "Ohha, oh, Frank hile, ....'.\n",
      "\n",
      "Richard:\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "# Example of generating output with the trained model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_output = generate_text(trained_model, initial_idx, block_size, max_new_tokens=2000)\n",
    "decoded_output = decode(generated_output[0].tolist())\n",
    "print(decoded_output)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
